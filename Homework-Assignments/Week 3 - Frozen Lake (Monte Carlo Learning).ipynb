{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/.conda/envs/py3k/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n",
      "/home/aditya/.conda/envs/py3k/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "import gym\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "game = gym.make('FrozenLake-v0')\n",
    "env = game.env\n",
    "policy_to_action = {0:'L',1:'D',2:'R',3:'U'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.9\n",
    "\n",
    "def epsilon_greedy(a,env,eps=0.1):\n",
    "    p = np.random.random()\n",
    "    if p < 1-eps: #exploit\n",
    "        return a\n",
    "    else: #explore\n",
    "        return np.random.randint(0,env.nA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(env,policy,EPSILON):\n",
    "    s = env.reset()\n",
    "    a = epsilon_greedy(policy[s],env,eps=EPSILON)\n",
    "    \n",
    "    #reward belong to one state and action before\n",
    "    state_action_reward = [(s,a,0)]\n",
    "    while True:\n",
    "        s,r,terminated,_ = env.step(a)\n",
    "        if terminated:\n",
    "            state_action_reward.append((s,None,r))\n",
    "            break\n",
    "        else:\n",
    "            a = epsilon_greedy(policy[s],env,eps=EPSILON)\n",
    "            state_action_reward.append((s,a,r))\n",
    "    G=0\n",
    "    state_action_return = []\n",
    "    first = True\n",
    "    for s,a,r in reversed(state_action_reward):\n",
    "        if first:\n",
    "            first=False\n",
    "        else:\n",
    "            state_action_return.append((s,a,G))\n",
    "            \n",
    "        G = r + GAMMA*G\n",
    "        state_action_return.reverse()\n",
    "    return state_action_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(env,EPSILON=0.5,N_EPISODES=10000):\n",
    "    policy = np.random.choice(env.nA,env.nS)\n",
    "    \n",
    "    Q = {}\n",
    "    visit = {}\n",
    "    for s in range(env.nS):\n",
    "        Q[s] = {}\n",
    "        visit[s] = {}\n",
    "        for a in range(env.nA):\n",
    "            Q[s][a] = 0\n",
    "            visit[s][a] = 0\n",
    "        \n",
    "    deltas = [] #keep track of learning curve\n",
    "    for i in tqdm(range(N_EPISODES),desc=\"Episodes Completed : \",leave=False):\n",
    "        \n",
    "        # epsilon decreasing\n",
    "        esp = max( 0, EPSILON - i/N_EPISODES )\n",
    "        \n",
    "        state_action_return = play_game(env,policy,esp)\n",
    "        seen_state_action = set()\n",
    "        biggest_change = 0\n",
    "        for s,a,G in state_action_return:\n",
    "            if (s,a) not in seen_state_action:\n",
    "                visit[s][a] += 1\n",
    "                oldq = Q[s][a]\n",
    "                #incremental mean\n",
    "                Q[s][a] = Q[s][a] + ( G - Q[s][a] )/visit[s][a]\n",
    "                seen_state_action.add((s,a))\n",
    "                biggest_change = max( biggest_change , np.abs(oldq - Q[s][a]) )\n",
    "        deltas.append(biggest_change)\n",
    "        \n",
    "        #update policy\n",
    "        for s in Q.keys():\n",
    "            best_a = None\n",
    "            best_G = float('-inf')\n",
    "            for a,G in Q[s].items():\n",
    "                if G > best_G:\n",
    "                    best_G = G\n",
    "                    best_a = a\n",
    "            policy[s] = best_a\n",
    "    \n",
    "    V = []\n",
    "    for s in Q.keys():\n",
    "        best_G = float('-inf')\n",
    "        for _,G in Q[s].items():\n",
    "            if G > best_G:\n",
    "                best_G = G\n",
    "        V.append(best_G)\n",
    "        \n",
    "    return V,policy,deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Episodes Completed : ', max=1000000, style=ProgressStyle(descâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "TIME TAKEN 528.1769874095917 seconds\n",
      "Optimal Policy :\n",
      " [['L' 'U' 'L' 'U']\n",
      " ['L' 'L' 'R' 'L']\n",
      " ['U' 'D' 'L' 'L']\n",
      " ['L' 'R' 'D' 'L']] \n",
      "Optimal Values :\n",
      " [[ 0.05925071  0.04690184  0.06774712  0.03214937]\n",
      " [ 0.09627629  0.          0.11809879  0.        ]\n",
      " [ 0.15593271  0.30300095  0.34321072  0.        ]\n",
      " [ 0.          0.41719     0.69457795  0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+kLzg0W2fgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff589d97518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "value,policy,Delta = monte_carlo(env,EPSILON=0.4,N_EPISODES=1000000)\n",
    "print('TIME TAKEN {} seconds'.format(time.time()-start))\n",
    "\n",
    "size=4\n",
    "gpolicy = list(map(lambda a: policy_to_action[a],policy))\n",
    "print(\"Optimal Policy :\\n {} \".format(np.reshape(gpolicy,(size,size))))\n",
    "print(\"Optimal Values :\\n {}\".format(np.reshape(value,(size,size))))\n",
    "\n",
    "plt.plot(Delta)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate : 0.735\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lets see our success rate\n",
    "\"\"\"\n",
    "games = 1000\n",
    "won = 0\n",
    "for _ in range(games):\n",
    "    state = game.reset()\n",
    "    while True:\n",
    "        action = int(policy[state])\n",
    "        (state,reward,is_done,_) = game.step(action)\n",
    "        if is_done:\n",
    "            if reward>0:\n",
    "                won+=1\n",
    "            game.close()\n",
    "            break\n",
    "            \n",
    "print(\"Success Rate : {}\".format(won/games))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the best anyone could get even if the env is deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
