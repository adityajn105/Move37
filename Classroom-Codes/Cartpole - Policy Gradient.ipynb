{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import ptan\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PGN(nn.Module):\n",
    "    def __init__(self,input_size,n_actions):\n",
    "        super(PGN,self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,n_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        logits = self.net(x)\n",
    "        return F.softmax(logits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeanBuffer():\n",
    "    def __init__(self,capacity):\n",
    "        self.capacity = capacity\n",
    "        self.deque = collections.deque(maxlen=capacity)\n",
    "        self.sum = 0.0\n",
    "        \n",
    "    def add(self,val):\n",
    "        if len(self.deque)==self.capacity:\n",
    "            self.sum -= self.deque[0]\n",
    "        self.deque.append(val)\n",
    "        self.sum+=val\n",
    "    \n",
    "    def mean(self):\n",
    "        if not self.deque:\n",
    "            return 0.0\n",
    "        return self.sum/len(self.deque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET_REWARD = 195\n",
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "ENTROPY_BETA = 0.01\n",
    "BELLMAN_STEPS = 10\n",
    "BASELINE_STEPS = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/.conda/envs/py3k/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n",
      "/home/aditya/.conda/envs/py3k/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17: reward:  16.00, mean_100:  16.00, episodes: 1\n",
      "30: reward:  12.00, mean_100:  14.00, episodes: 2\n",
      "46: reward:  15.00, mean_100:  14.33, episodes: 3\n",
      "86: reward:  39.00, mean_100:  20.50, episodes: 4\n",
      "100: reward:  13.00, mean_100:  19.00, episodes: 5\n",
      "122: reward:  21.00, mean_100:  19.33, episodes: 6\n",
      "137: reward:  14.00, mean_100:  18.57, episodes: 7\n",
      "146: reward:   9.00, mean_100:  17.38, episodes: 8\n",
      "167: reward:  20.00, mean_100:  17.67, episodes: 9\n",
      "201: reward:  33.00, mean_100:  19.20, episodes: 10\n",
      "220: reward:  18.00, mean_100:  19.09, episodes: 11\n",
      "241: reward:  20.00, mean_100:  19.17, episodes: 12\n",
      "262: reward:  20.00, mean_100:  19.23, episodes: 13\n",
      "289: reward:  26.00, mean_100:  19.71, episodes: 14\n",
      "310: reward:  20.00, mean_100:  19.73, episodes: 15\n",
      "323: reward:  12.00, mean_100:  19.25, episodes: 16\n",
      "337: reward:  13.00, mean_100:  18.88, episodes: 17\n",
      "362: reward:  24.00, mean_100:  19.17, episodes: 18\n",
      "375: reward:  12.00, mean_100:  18.79, episodes: 19\n",
      "405: reward:  29.00, mean_100:  19.30, episodes: 20\n",
      "426: reward:  20.00, mean_100:  19.33, episodes: 21\n",
      "450: reward:  23.00, mean_100:  19.50, episodes: 22\n",
      "469: reward:  18.00, mean_100:  19.43, episodes: 23\n",
      "488: reward:  18.00, mean_100:  19.38, episodes: 24\n",
      "497: reward:   9.00, mean_100:  18.96, episodes: 25\n",
      "514: reward:  16.00, mean_100:  18.85, episodes: 26\n",
      "555: reward:  40.00, mean_100:  19.63, episodes: 27\n",
      "574: reward:  18.00, mean_100:  19.57, episodes: 28\n",
      "583: reward:   9.00, mean_100:  19.21, episodes: 29\n",
      "617: reward:  33.00, mean_100:  19.67, episodes: 30\n",
      "655: reward:  37.00, mean_100:  20.23, episodes: 31\n",
      "686: reward:  30.00, mean_100:  20.53, episodes: 32\n",
      "707: reward:  20.00, mean_100:  20.52, episodes: 33\n",
      "746: reward:  38.00, mean_100:  21.03, episodes: 34\n",
      "773: reward:  26.00, mean_100:  21.17, episodes: 35\n",
      "787: reward:  13.00, mean_100:  20.94, episodes: 36\n",
      "803: reward:  15.00, mean_100:  20.78, episodes: 37\n",
      "893: reward:  89.00, mean_100:  22.58, episodes: 38\n",
      "913: reward:  19.00, mean_100:  22.49, episodes: 39\n",
      "933: reward:  19.00, mean_100:  22.40, episodes: 40\n",
      "971: reward:  37.00, mean_100:  22.76, episodes: 41\n",
      "988: reward:  16.00, mean_100:  22.60, episodes: 42\n",
      "1008: reward:  19.00, mean_100:  22.51, episodes: 43\n",
      "1041: reward:  32.00, mean_100:  22.73, episodes: 44\n",
      "1064: reward:  22.00, mean_100:  22.71, episodes: 45\n",
      "1081: reward:  16.00, mean_100:  22.57, episodes: 46\n",
      "1106: reward:  24.00, mean_100:  22.60, episodes: 47\n",
      "1167: reward:  60.00, mean_100:  23.38, episodes: 48\n",
      "1200: reward:  32.00, mean_100:  23.55, episodes: 49\n",
      "1228: reward:  27.00, mean_100:  23.62, episodes: 50\n",
      "1249: reward:  20.00, mean_100:  23.55, episodes: 51\n",
      "1287: reward:  37.00, mean_100:  23.81, episodes: 52\n",
      "1320: reward:  32.00, mean_100:  23.96, episodes: 53\n",
      "1358: reward:  37.00, mean_100:  24.20, episodes: 54\n",
      "1385: reward:  26.00, mean_100:  24.24, episodes: 55\n",
      "1418: reward:  32.00, mean_100:  24.38, episodes: 56\n",
      "1437: reward:  18.00, mean_100:  24.26, episodes: 57\n",
      "1463: reward:  25.00, mean_100:  24.28, episodes: 58\n",
      "1493: reward:  29.00, mean_100:  24.36, episodes: 59\n",
      "1580: reward:  86.00, mean_100:  25.38, episodes: 60\n",
      "1596: reward:  15.00, mean_100:  25.21, episodes: 61\n",
      "1633: reward:  36.00, mean_100:  25.39, episodes: 62\n",
      "1674: reward:  40.00, mean_100:  25.62, episodes: 63\n",
      "1743: reward:  68.00, mean_100:  26.28, episodes: 64\n",
      "1788: reward:  44.00, mean_100:  26.55, episodes: 65\n",
      "1871: reward:  82.00, mean_100:  27.39, episodes: 66\n",
      "1893: reward:  21.00, mean_100:  27.30, episodes: 67\n",
      "1915: reward:  21.00, mean_100:  27.21, episodes: 68\n",
      "1944: reward:  28.00, mean_100:  27.22, episodes: 69\n",
      "1990: reward:  45.00, mean_100:  27.47, episodes: 70\n",
      "2028: reward:  37.00, mean_100:  27.61, episodes: 71\n",
      "2075: reward:  46.00, mean_100:  27.86, episodes: 72\n",
      "2092: reward:  16.00, mean_100:  27.70, episodes: 73\n",
      "2106: reward:  13.00, mean_100:  27.50, episodes: 74\n",
      "2151: reward:  44.00, mean_100:  27.72, episodes: 75\n",
      "2180: reward:  28.00, mean_100:  27.72, episodes: 76\n",
      "2224: reward:  43.00, mean_100:  27.92, episodes: 77\n",
      "2277: reward:  52.00, mean_100:  28.23, episodes: 78\n",
      "2301: reward:  23.00, mean_100:  28.16, episodes: 79\n",
      "2416: reward: 114.00, mean_100:  29.24, episodes: 80\n",
      "2440: reward:  23.00, mean_100:  29.16, episodes: 81\n",
      "2485: reward:  44.00, mean_100:  29.34, episodes: 82\n",
      "2553: reward:  67.00, mean_100:  29.80, episodes: 83\n",
      "2569: reward:  15.00, mean_100:  29.62, episodes: 84\n",
      "2617: reward:  47.00, mean_100:  29.82, episodes: 85\n",
      "2666: reward:  48.00, mean_100:  30.03, episodes: 86\n",
      "2695: reward:  28.00, mean_100:  30.01, episodes: 87\n",
      "2739: reward:  43.00, mean_100:  30.16, episodes: 88\n",
      "2777: reward:  37.00, mean_100:  30.24, episodes: 89\n",
      "2807: reward:  29.00, mean_100:  30.22, episodes: 90\n",
      "2844: reward:  36.00, mean_100:  30.29, episodes: 91\n",
      "2872: reward:  27.00, mean_100:  30.25, episodes: 92\n",
      "2887: reward:  14.00, mean_100:  30.08, episodes: 93\n",
      "2915: reward:  27.00, mean_100:  30.04, episodes: 94\n",
      "2943: reward:  27.00, mean_100:  30.01, episodes: 95\n",
      "3051: reward: 107.00, mean_100:  30.81, episodes: 96\n",
      "3069: reward:  17.00, mean_100:  30.67, episodes: 97\n",
      "3145: reward:  75.00, mean_100:  31.12, episodes: 98\n",
      "3191: reward:  45.00, mean_100:  31.26, episodes: 99\n",
      "3224: reward:  32.00, mean_100:  31.27, episodes: 100\n",
      "3259: reward:  34.00, mean_100:  31.45, episodes: 101\n",
      "3341: reward:  81.00, mean_100:  32.14, episodes: 102\n",
      "3356: reward:  14.00, mean_100:  32.13, episodes: 103\n",
      "3392: reward:  35.00, mean_100:  32.09, episodes: 104\n",
      "3405: reward:  12.00, mean_100:  32.08, episodes: 105\n",
      "3431: reward:  25.00, mean_100:  32.12, episodes: 106\n",
      "3455: reward:  23.00, mean_100:  32.21, episodes: 107\n",
      "3469: reward:  13.00, mean_100:  32.25, episodes: 108\n",
      "3488: reward:  18.00, mean_100:  32.23, episodes: 109\n",
      "3524: reward:  35.00, mean_100:  32.25, episodes: 110\n",
      "3561: reward:  36.00, mean_100:  32.43, episodes: 111\n",
      "3602: reward:  40.00, mean_100:  32.63, episodes: 112\n",
      "3644: reward:  41.00, mean_100:  32.84, episodes: 113\n",
      "3686: reward:  41.00, mean_100:  32.99, episodes: 114\n",
      "3732: reward:  45.00, mean_100:  33.24, episodes: 115\n",
      "3801: reward:  68.00, mean_100:  33.80, episodes: 116\n",
      "3833: reward:  31.00, mean_100:  33.98, episodes: 117\n",
      "3870: reward:  36.00, mean_100:  34.10, episodes: 118\n",
      "3922: reward:  51.00, mean_100:  34.49, episodes: 119\n",
      "3951: reward:  28.00, mean_100:  34.48, episodes: 120\n",
      "3972: reward:  20.00, mean_100:  34.48, episodes: 121\n",
      "4035: reward:  62.00, mean_100:  34.87, episodes: 122\n",
      "4062: reward:  26.00, mean_100:  34.95, episodes: 123\n",
      "4092: reward:  29.00, mean_100:  35.06, episodes: 124\n",
      "4115: reward:  22.00, mean_100:  35.19, episodes: 125\n",
      "4206: reward:  90.00, mean_100:  35.93, episodes: 126\n",
      "4254: reward:  47.00, mean_100:  36.00, episodes: 127\n",
      "4370: reward: 115.00, mean_100:  36.97, episodes: 128\n",
      "4389: reward:  18.00, mean_100:  37.06, episodes: 129\n",
      "4419: reward:  29.00, mean_100:  37.02, episodes: 130\n",
      "4460: reward:  40.00, mean_100:  37.05, episodes: 131\n",
      "4510: reward:  49.00, mean_100:  37.24, episodes: 132\n",
      "4549: reward:  38.00, mean_100:  37.42, episodes: 133\n",
      "4604: reward:  54.00, mean_100:  37.58, episodes: 134\n",
      "4630: reward:  25.00, mean_100:  37.57, episodes: 135\n",
      "4647: reward:  16.00, mean_100:  37.60, episodes: 136\n",
      "4804: reward: 156.00, mean_100:  39.01, episodes: 137\n",
      "4840: reward:  35.00, mean_100:  38.47, episodes: 138\n",
      "4880: reward:  39.00, mean_100:  38.67, episodes: 139\n",
      "4932: reward:  51.00, mean_100:  38.99, episodes: 140\n",
      "4964: reward:  31.00, mean_100:  38.93, episodes: 141\n",
      "5041: reward:  76.00, mean_100:  39.53, episodes: 142\n",
      "5080: reward:  38.00, mean_100:  39.72, episodes: 143\n",
      "5145: reward:  64.00, mean_100:  40.04, episodes: 144\n",
      "5234: reward:  88.00, mean_100:  40.70, episodes: 145\n",
      "5280: reward:  45.00, mean_100:  40.99, episodes: 146\n",
      "5331: reward:  50.00, mean_100:  41.25, episodes: 147\n",
      "5387: reward:  55.00, mean_100:  41.20, episodes: 148\n",
      "5441: reward:  53.00, mean_100:  41.41, episodes: 149\n",
      "5551: reward: 109.00, mean_100:  42.23, episodes: 150\n",
      "5571: reward:  19.00, mean_100:  42.22, episodes: 151\n",
      "5628: reward:  56.00, mean_100:  42.41, episodes: 152\n",
      "5706: reward:  77.00, mean_100:  42.86, episodes: 153\n",
      "5859: reward: 152.00, mean_100:  44.01, episodes: 154\n",
      "5912: reward:  52.00, mean_100:  44.27, episodes: 155\n",
      "5951: reward:  38.00, mean_100:  44.33, episodes: 156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6003: reward:  51.00, mean_100:  44.66, episodes: 157\n",
      "6065: reward:  61.00, mean_100:  45.02, episodes: 158\n",
      "6114: reward:  48.00, mean_100:  45.21, episodes: 159\n",
      "6152: reward:  37.00, mean_100:  44.72, episodes: 160\n",
      "6195: reward:  42.00, mean_100:  44.99, episodes: 161\n",
      "6293: reward:  97.00, mean_100:  45.60, episodes: 162\n",
      "6317: reward:  23.00, mean_100:  45.43, episodes: 163\n",
      "6383: reward:  65.00, mean_100:  45.40, episodes: 164\n",
      "6435: reward:  51.00, mean_100:  45.47, episodes: 165\n",
      "6497: reward:  61.00, mean_100:  45.26, episodes: 166\n",
      "6576: reward:  78.00, mean_100:  45.83, episodes: 167\n",
      "6629: reward:  52.00, mean_100:  46.14, episodes: 168\n",
      "6795: reward: 165.00, mean_100:  47.51, episodes: 169\n",
      "6842: reward:  46.00, mean_100:  47.52, episodes: 170\n",
      "6911: reward:  68.00, mean_100:  47.83, episodes: 171\n",
      "7001: reward:  89.00, mean_100:  48.26, episodes: 172\n",
      "7050: reward:  48.00, mean_100:  48.58, episodes: 173\n",
      "7087: reward:  36.00, mean_100:  48.81, episodes: 174\n",
      "7121: reward:  33.00, mean_100:  48.70, episodes: 175\n",
      "7187: reward:  65.00, mean_100:  49.07, episodes: 176\n",
      "7294: reward: 106.00, mean_100:  49.70, episodes: 177\n",
      "7346: reward:  51.00, mean_100:  49.69, episodes: 178\n",
      "7401: reward:  54.00, mean_100:  50.00, episodes: 179\n",
      "7602: reward: 200.00, mean_100:  50.86, episodes: 180\n",
      "7640: reward:  37.00, mean_100:  51.00, episodes: 181\n",
      "7671: reward:  30.00, mean_100:  50.86, episodes: 182\n",
      "7702: reward:  30.00, mean_100:  50.49, episodes: 183\n",
      "7772: reward:  69.00, mean_100:  51.03, episodes: 184\n",
      "7806: reward:  33.00, mean_100:  50.89, episodes: 185\n",
      "7862: reward:  55.00, mean_100:  50.96, episodes: 186\n",
      "7939: reward:  76.00, mean_100:  51.44, episodes: 187\n",
      "8041: reward: 101.00, mean_100:  52.02, episodes: 188\n",
      "8160: reward: 118.00, mean_100:  52.83, episodes: 189\n",
      "8271: reward: 110.00, mean_100:  53.64, episodes: 190\n",
      "8337: reward:  65.00, mean_100:  53.93, episodes: 191\n",
      "8367: reward:  29.00, mean_100:  53.95, episodes: 192\n",
      "8515: reward: 147.00, mean_100:  55.28, episodes: 193\n",
      "8581: reward:  65.00, mean_100:  55.66, episodes: 194\n",
      "8649: reward:  67.00, mean_100:  56.06, episodes: 195\n",
      "8781: reward: 131.00, mean_100:  56.30, episodes: 196\n",
      "8982: reward: 200.00, mean_100:  58.13, episodes: 197\n",
      "9037: reward:  54.00, mean_100:  57.92, episodes: 198\n",
      "9210: reward: 172.00, mean_100:  59.19, episodes: 199\n",
      "9286: reward:  75.00, mean_100:  59.62, episodes: 200\n",
      "9361: reward:  74.00, mean_100:  60.02, episodes: 201\n",
      "9462: reward: 100.00, mean_100:  60.21, episodes: 202\n",
      "9541: reward:  78.00, mean_100:  60.85, episodes: 203\n",
      "9657: reward: 115.00, mean_100:  61.65, episodes: 204\n",
      "9858: reward: 200.00, mean_100:  63.53, episodes: 205\n",
      "9996: reward: 137.00, mean_100:  64.65, episodes: 206\n",
      "10033: reward:  36.00, mean_100:  64.78, episodes: 207\n",
      "10059: reward:  25.00, mean_100:  64.90, episodes: 208\n",
      "10214: reward: 154.00, mean_100:  66.26, episodes: 209\n",
      "10340: reward: 125.00, mean_100:  67.16, episodes: 210\n",
      "10472: reward: 131.00, mean_100:  68.11, episodes: 211\n",
      "10582: reward: 109.00, mean_100:  68.80, episodes: 212\n",
      "10746: reward: 163.00, mean_100:  70.02, episodes: 213\n",
      "10947: reward: 200.00, mean_100:  71.61, episodes: 214\n",
      "11010: reward:  62.00, mean_100:  71.78, episodes: 215\n",
      "11101: reward:  90.00, mean_100:  72.00, episodes: 216\n",
      "11302: reward: 200.00, mean_100:  73.69, episodes: 217\n",
      "11347: reward:  44.00, mean_100:  73.77, episodes: 218\n",
      "11530: reward: 182.00, mean_100:  75.08, episodes: 219\n",
      "11731: reward: 200.00, mean_100:  76.80, episodes: 220\n",
      "11889: reward: 157.00, mean_100:  78.17, episodes: 221\n",
      "12043: reward: 153.00, mean_100:  79.08, episodes: 222\n",
      "12170: reward: 126.00, mean_100:  80.08, episodes: 223\n",
      "12371: reward: 200.00, mean_100:  81.79, episodes: 224\n",
      "12515: reward: 143.00, mean_100:  83.00, episodes: 225\n",
      "12602: reward:  86.00, mean_100:  82.96, episodes: 226\n",
      "12766: reward: 163.00, mean_100:  84.12, episodes: 227\n",
      "12937: reward: 170.00, mean_100:  84.67, episodes: 228\n",
      "13046: reward: 108.00, mean_100:  85.57, episodes: 229\n",
      "13167: reward: 120.00, mean_100:  86.48, episodes: 230\n",
      "13368: reward: 200.00, mean_100:  88.08, episodes: 231\n",
      "13515: reward: 146.00, mean_100:  89.05, episodes: 232\n",
      "13653: reward: 137.00, mean_100:  90.04, episodes: 233\n",
      "13761: reward: 107.00, mean_100:  90.57, episodes: 234\n",
      "13962: reward: 200.00, mean_100:  92.32, episodes: 235\n",
      "14163: reward: 200.00, mean_100:  94.16, episodes: 236\n",
      "14364: reward: 200.00, mean_100:  94.60, episodes: 237\n",
      "14555: reward: 190.00, mean_100:  96.15, episodes: 238\n",
      "14590: reward:  34.00, mean_100:  96.10, episodes: 239\n",
      "14739: reward: 148.00, mean_100:  97.07, episodes: 240\n",
      "14917: reward: 177.00, mean_100:  98.53, episodes: 241\n",
      "15055: reward: 137.00, mean_100:  99.14, episodes: 242\n",
      "15192: reward: 136.00, mean_100: 100.12, episodes: 243\n",
      "15249: reward:  56.00, mean_100: 100.04, episodes: 244\n",
      "15380: reward: 130.00, mean_100: 100.46, episodes: 245\n",
      "15493: reward: 112.00, mean_100: 101.13, episodes: 246\n",
      "15688: reward: 194.00, mean_100: 102.57, episodes: 247\n",
      "15848: reward: 159.00, mean_100: 103.61, episodes: 248\n",
      "15949: reward: 100.00, mean_100: 104.08, episodes: 249\n",
      "16112: reward: 162.00, mean_100: 104.61, episodes: 250\n",
      "16313: reward: 200.00, mean_100: 106.42, episodes: 251\n",
      "16480: reward: 166.00, mean_100: 107.52, episodes: 252\n",
      "16592: reward: 111.00, mean_100: 107.86, episodes: 253\n",
      "16698: reward: 105.00, mean_100: 107.39, episodes: 254\n",
      "16899: reward: 200.00, mean_100: 108.87, episodes: 255\n",
      "17100: reward: 200.00, mean_100: 110.49, episodes: 256\n",
      "17247: reward: 146.00, mean_100: 111.44, episodes: 257\n",
      "17421: reward: 173.00, mean_100: 112.56, episodes: 258\n",
      "17563: reward: 141.00, mean_100: 113.49, episodes: 259\n",
      "17610: reward:  46.00, mean_100: 113.58, episodes: 260\n",
      "17786: reward: 175.00, mean_100: 114.91, episodes: 261\n",
      "17909: reward: 122.00, mean_100: 115.16, episodes: 262\n",
      "18052: reward: 142.00, mean_100: 116.35, episodes: 263\n",
      "18145: reward:  92.00, mean_100: 116.62, episodes: 264\n",
      "18295: reward: 149.00, mean_100: 117.60, episodes: 265\n",
      "18447: reward: 151.00, mean_100: 118.50, episodes: 266\n",
      "18648: reward: 200.00, mean_100: 119.72, episodes: 267\n",
      "18849: reward: 200.00, mean_100: 121.20, episodes: 268\n",
      "18993: reward: 143.00, mean_100: 120.98, episodes: 269\n",
      "19030: reward:  36.00, mean_100: 120.88, episodes: 270\n",
      "19153: reward: 122.00, mean_100: 121.42, episodes: 271\n",
      "19354: reward: 200.00, mean_100: 122.53, episodes: 272\n",
      "19555: reward: 200.00, mean_100: 124.05, episodes: 273\n",
      "19709: reward: 153.00, mean_100: 125.22, episodes: 274\n",
      "19910: reward: 200.00, mean_100: 126.89, episodes: 275\n",
      "19984: reward:  73.00, mean_100: 126.97, episodes: 276\n",
      "20176: reward: 191.00, mean_100: 127.82, episodes: 277\n",
      "20259: reward:  82.00, mean_100: 128.13, episodes: 278\n",
      "20460: reward: 200.00, mean_100: 129.59, episodes: 279\n",
      "20612: reward: 151.00, mean_100: 129.10, episodes: 280\n",
      "20760: reward: 147.00, mean_100: 130.20, episodes: 281\n",
      "20961: reward: 200.00, mean_100: 131.90, episodes: 282\n",
      "21162: reward: 200.00, mean_100: 133.60, episodes: 283\n",
      "21363: reward: 200.00, mean_100: 134.91, episodes: 284\n",
      "21564: reward: 200.00, mean_100: 136.58, episodes: 285\n",
      "21753: reward: 188.00, mean_100: 137.91, episodes: 286\n",
      "21925: reward: 171.00, mean_100: 138.86, episodes: 287\n",
      "22119: reward: 193.00, mean_100: 139.78, episodes: 288\n",
      "22262: reward: 142.00, mean_100: 140.02, episodes: 289\n",
      "22463: reward: 200.00, mean_100: 140.92, episodes: 290\n",
      "22619: reward: 155.00, mean_100: 141.82, episodes: 291\n",
      "22748: reward: 128.00, mean_100: 142.81, episodes: 292\n",
      "22831: reward:  82.00, mean_100: 142.16, episodes: 293\n",
      "23032: reward: 200.00, mean_100: 143.51, episodes: 294\n",
      "23233: reward: 200.00, mean_100: 144.84, episodes: 295\n",
      "23284: reward:  50.00, mean_100: 144.03, episodes: 296\n",
      "23421: reward: 136.00, mean_100: 143.39, episodes: 297\n",
      "23576: reward: 154.00, mean_100: 144.39, episodes: 298\n",
      "23686: reward: 109.00, mean_100: 143.76, episodes: 299\n",
      "23819: reward: 132.00, mean_100: 144.33, episodes: 300\n",
      "23969: reward: 149.00, mean_100: 145.08, episodes: 301\n",
      "24157: reward: 187.00, mean_100: 145.95, episodes: 302\n",
      "24217: reward:  59.00, mean_100: 145.76, episodes: 303\n",
      "24418: reward: 200.00, mean_100: 146.61, episodes: 304\n",
      "24619: reward: 200.00, mean_100: 146.61, episodes: 305\n",
      "24820: reward: 200.00, mean_100: 147.24, episodes: 306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25021: reward: 200.00, mean_100: 148.88, episodes: 307\n",
      "25141: reward: 119.00, mean_100: 149.82, episodes: 308\n",
      "25342: reward: 200.00, mean_100: 150.28, episodes: 309\n",
      "25536: reward: 193.00, mean_100: 150.96, episodes: 310\n",
      "25721: reward: 184.00, mean_100: 151.49, episodes: 311\n",
      "25922: reward: 200.00, mean_100: 152.40, episodes: 312\n",
      "26073: reward: 150.00, mean_100: 152.27, episodes: 313\n",
      "26274: reward: 200.00, mean_100: 152.27, episodes: 314\n",
      "26433: reward: 158.00, mean_100: 153.23, episodes: 315\n",
      "26634: reward: 200.00, mean_100: 154.33, episodes: 316\n",
      "26713: reward:  78.00, mean_100: 153.11, episodes: 317\n",
      "26851: reward: 137.00, mean_100: 154.04, episodes: 318\n",
      "27052: reward: 200.00, mean_100: 154.22, episodes: 319\n",
      "27167: reward: 114.00, mean_100: 153.36, episodes: 320\n",
      "27368: reward: 200.00, mean_100: 153.79, episodes: 321\n",
      "27569: reward: 200.00, mean_100: 154.26, episodes: 322\n",
      "27770: reward: 200.00, mean_100: 155.00, episodes: 323\n",
      "27949: reward: 178.00, mean_100: 154.78, episodes: 324\n",
      "28126: reward: 176.00, mean_100: 155.11, episodes: 325\n",
      "28327: reward: 200.00, mean_100: 156.25, episodes: 326\n",
      "28528: reward: 200.00, mean_100: 156.62, episodes: 327\n",
      "28729: reward: 200.00, mean_100: 156.92, episodes: 328\n",
      "28915: reward: 185.00, mean_100: 157.69, episodes: 329\n",
      "29116: reward: 200.00, mean_100: 158.49, episodes: 330\n",
      "29317: reward: 200.00, mean_100: 158.49, episodes: 331\n",
      "29448: reward: 130.00, mean_100: 158.33, episodes: 332\n",
      "29649: reward: 200.00, mean_100: 158.96, episodes: 333\n",
      "29846: reward: 196.00, mean_100: 159.85, episodes: 334\n",
      "30047: reward: 200.00, mean_100: 159.85, episodes: 335\n",
      "30220: reward: 172.00, mean_100: 159.57, episodes: 336\n",
      "30390: reward: 169.00, mean_100: 159.26, episodes: 337\n",
      "30513: reward: 122.00, mean_100: 158.58, episodes: 338\n",
      "30706: reward: 192.00, mean_100: 160.16, episodes: 339\n",
      "30907: reward: 200.00, mean_100: 160.68, episodes: 340\n",
      "31051: reward: 143.00, mean_100: 160.34, episodes: 341\n",
      "31252: reward: 200.00, mean_100: 160.97, episodes: 342\n",
      "31409: reward: 156.00, mean_100: 161.17, episodes: 343\n",
      "31610: reward: 200.00, mean_100: 162.61, episodes: 344\n",
      "31777: reward: 166.00, mean_100: 162.97, episodes: 345\n",
      "31978: reward: 200.00, mean_100: 163.85, episodes: 346\n",
      "32179: reward: 200.00, mean_100: 163.91, episodes: 347\n",
      "32380: reward: 200.00, mean_100: 164.32, episodes: 348\n",
      "32581: reward: 200.00, mean_100: 165.32, episodes: 349\n",
      "32782: reward: 200.00, mean_100: 165.70, episodes: 350\n",
      "32983: reward: 200.00, mean_100: 165.70, episodes: 351\n",
      "33184: reward: 200.00, mean_100: 166.04, episodes: 352\n",
      "33385: reward: 200.00, mean_100: 166.93, episodes: 353\n",
      "33586: reward: 200.00, mean_100: 167.88, episodes: 354\n",
      "33744: reward: 157.00, mean_100: 167.45, episodes: 355\n",
      "33945: reward: 200.00, mean_100: 167.45, episodes: 356\n",
      "34146: reward: 200.00, mean_100: 167.99, episodes: 357\n",
      "34341: reward: 194.00, mean_100: 168.20, episodes: 358\n",
      "34542: reward: 200.00, mean_100: 168.79, episodes: 359\n",
      "34743: reward: 200.00, mean_100: 170.33, episodes: 360\n",
      "34900: reward: 156.00, mean_100: 170.14, episodes: 361\n",
      "35048: reward: 147.00, mean_100: 170.39, episodes: 362\n",
      "35249: reward: 200.00, mean_100: 170.97, episodes: 363\n",
      "35330: reward:  80.00, mean_100: 170.85, episodes: 364\n",
      "35531: reward: 200.00, mean_100: 171.36, episodes: 365\n",
      "35732: reward: 200.00, mean_100: 171.85, episodes: 366\n",
      "35850: reward: 117.00, mean_100: 171.02, episodes: 367\n",
      "36051: reward: 200.00, mean_100: 171.02, episodes: 368\n",
      "36252: reward: 200.00, mean_100: 171.59, episodes: 369\n",
      "36453: reward: 200.00, mean_100: 173.23, episodes: 370\n",
      "36614: reward: 160.00, mean_100: 173.61, episodes: 371\n",
      "36815: reward: 200.00, mean_100: 173.61, episodes: 372\n",
      "37016: reward: 200.00, mean_100: 173.61, episodes: 373\n",
      "37217: reward: 200.00, mean_100: 174.08, episodes: 374\n",
      "37418: reward: 200.00, mean_100: 174.08, episodes: 375\n",
      "37619: reward: 200.00, mean_100: 175.35, episodes: 376\n",
      "37820: reward: 200.00, mean_100: 175.44, episodes: 377\n",
      "38021: reward: 200.00, mean_100: 176.62, episodes: 378\n",
      "38222: reward: 200.00, mean_100: 176.62, episodes: 379\n",
      "38396: reward: 173.00, mean_100: 176.84, episodes: 380\n",
      "38597: reward: 200.00, mean_100: 177.37, episodes: 381\n",
      "38798: reward: 200.00, mean_100: 177.37, episodes: 382\n",
      "38999: reward: 200.00, mean_100: 177.37, episodes: 383\n",
      "39149: reward: 149.00, mean_100: 176.86, episodes: 384\n",
      "39350: reward: 200.00, mean_100: 176.86, episodes: 385\n",
      "39548: reward: 197.00, mean_100: 176.95, episodes: 386\n",
      "39749: reward: 200.00, mean_100: 177.24, episodes: 387\n",
      "39950: reward: 200.00, mean_100: 177.31, episodes: 388\n",
      "40150: reward: 199.00, mean_100: 177.88, episodes: 389\n",
      "40292: reward: 141.00, mean_100: 177.29, episodes: 390\n",
      "40422: reward: 129.00, mean_100: 177.03, episodes: 391\n",
      "40623: reward: 200.00, mean_100: 177.75, episodes: 392\n",
      "40823: reward: 199.00, mean_100: 178.92, episodes: 393\n",
      "40970: reward: 146.00, mean_100: 178.38, episodes: 394\n",
      "41157: reward: 186.00, mean_100: 178.24, episodes: 395\n",
      "41295: reward: 137.00, mean_100: 179.11, episodes: 396\n",
      "41496: reward: 200.00, mean_100: 179.75, episodes: 397\n",
      "41694: reward: 197.00, mean_100: 180.18, episodes: 398\n",
      "41895: reward: 200.00, mean_100: 181.09, episodes: 399\n",
      "42096: reward: 200.00, mean_100: 181.77, episodes: 400\n",
      "42297: reward: 200.00, mean_100: 182.28, episodes: 401\n",
      "42498: reward: 200.00, mean_100: 182.41, episodes: 402\n",
      "42699: reward: 200.00, mean_100: 183.82, episodes: 403\n",
      "42900: reward: 200.00, mean_100: 183.82, episodes: 404\n",
      "43101: reward: 200.00, mean_100: 183.82, episodes: 405\n",
      "43302: reward: 200.00, mean_100: 183.82, episodes: 406\n",
      "43487: reward: 184.00, mean_100: 183.66, episodes: 407\n",
      "43688: reward: 200.00, mean_100: 184.47, episodes: 408\n",
      "43858: reward: 169.00, mean_100: 184.16, episodes: 409\n",
      "44059: reward: 200.00, mean_100: 184.23, episodes: 410\n",
      "44260: reward: 200.00, mean_100: 184.39, episodes: 411\n",
      "44461: reward: 200.00, mean_100: 184.39, episodes: 412\n",
      "44662: reward: 200.00, mean_100: 184.89, episodes: 413\n",
      "44863: reward: 200.00, mean_100: 184.89, episodes: 414\n",
      "45064: reward: 200.00, mean_100: 185.31, episodes: 415\n",
      "45265: reward: 200.00, mean_100: 185.31, episodes: 416\n",
      "45466: reward: 200.00, mean_100: 186.53, episodes: 417\n",
      "45667: reward: 200.00, mean_100: 187.16, episodes: 418\n",
      "45847: reward: 179.00, mean_100: 186.95, episodes: 419\n",
      "46048: reward: 200.00, mean_100: 187.81, episodes: 420\n",
      "46194: reward: 145.00, mean_100: 187.26, episodes: 421\n",
      "46380: reward: 185.00, mean_100: 187.11, episodes: 422\n",
      "46581: reward: 200.00, mean_100: 187.11, episodes: 423\n",
      "46782: reward: 200.00, mean_100: 187.33, episodes: 424\n",
      "46983: reward: 200.00, mean_100: 187.57, episodes: 425\n",
      "47184: reward: 200.00, mean_100: 187.57, episodes: 426\n",
      "47385: reward: 200.00, mean_100: 187.57, episodes: 427\n",
      "47586: reward: 200.00, mean_100: 187.57, episodes: 428\n",
      "47787: reward: 200.00, mean_100: 187.72, episodes: 429\n",
      "47988: reward: 200.00, mean_100: 187.72, episodes: 430\n",
      "48189: reward: 200.00, mean_100: 187.72, episodes: 431\n",
      "48390: reward: 200.00, mean_100: 188.42, episodes: 432\n",
      "48591: reward: 200.00, mean_100: 188.42, episodes: 433\n",
      "48792: reward: 200.00, mean_100: 188.46, episodes: 434\n",
      "48993: reward: 200.00, mean_100: 188.46, episodes: 435\n",
      "49194: reward: 200.00, mean_100: 188.74, episodes: 436\n",
      "49395: reward: 200.00, mean_100: 189.05, episodes: 437\n",
      "49596: reward: 200.00, mean_100: 189.83, episodes: 438\n",
      "49797: reward: 200.00, mean_100: 189.91, episodes: 439\n",
      "49998: reward: 200.00, mean_100: 189.91, episodes: 440\n",
      "50199: reward: 200.00, mean_100: 190.48, episodes: 441\n",
      "50400: reward: 200.00, mean_100: 190.48, episodes: 442\n",
      "50601: reward: 200.00, mean_100: 190.92, episodes: 443\n",
      "50802: reward: 200.00, mean_100: 190.92, episodes: 444\n",
      "51003: reward: 200.00, mean_100: 191.26, episodes: 445\n",
      "51174: reward: 170.00, mean_100: 190.96, episodes: 446\n",
      "51372: reward: 197.00, mean_100: 190.93, episodes: 447\n",
      "51573: reward: 200.00, mean_100: 190.93, episodes: 448\n",
      "51774: reward: 200.00, mean_100: 190.93, episodes: 449\n",
      "51975: reward: 200.00, mean_100: 190.93, episodes: 450\n",
      "52176: reward: 200.00, mean_100: 190.93, episodes: 451\n",
      "52377: reward: 200.00, mean_100: 190.93, episodes: 452\n",
      "52578: reward: 200.00, mean_100: 190.93, episodes: 453\n",
      "52779: reward: 200.00, mean_100: 190.93, episodes: 454\n",
      "52980: reward: 200.00, mean_100: 191.36, episodes: 455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53181: reward: 200.00, mean_100: 191.36, episodes: 456\n",
      "53382: reward: 200.00, mean_100: 191.36, episodes: 457\n",
      "53498: reward: 115.00, mean_100: 190.57, episodes: 458\n",
      "53666: reward: 167.00, mean_100: 190.24, episodes: 459\n",
      "53806: reward: 139.00, mean_100: 189.63, episodes: 460\n",
      "53939: reward: 132.00, mean_100: 189.39, episodes: 461\n",
      "54140: reward: 200.00, mean_100: 189.92, episodes: 462\n",
      "54313: reward: 172.00, mean_100: 189.64, episodes: 463\n",
      "54452: reward: 138.00, mean_100: 190.22, episodes: 464\n",
      "54647: reward: 194.00, mean_100: 190.16, episodes: 465\n",
      "54848: reward: 200.00, mean_100: 190.16, episodes: 466\n",
      "55049: reward: 200.00, mean_100: 190.99, episodes: 467\n",
      "55166: reward: 116.00, mean_100: 190.15, episodes: 468\n",
      "55367: reward: 200.00, mean_100: 190.15, episodes: 469\n",
      "55568: reward: 200.00, mean_100: 190.15, episodes: 470\n",
      "55769: reward: 200.00, mean_100: 190.55, episodes: 471\n",
      "55940: reward: 170.00, mean_100: 190.25, episodes: 472\n",
      "56140: reward: 199.00, mean_100: 190.24, episodes: 473\n",
      "56311: reward: 170.00, mean_100: 189.94, episodes: 474\n",
      "56512: reward: 200.00, mean_100: 189.94, episodes: 475\n",
      "56690: reward: 177.00, mean_100: 189.71, episodes: 476\n",
      "56873: reward: 182.00, mean_100: 189.53, episodes: 477\n",
      "56959: reward:  85.00, mean_100: 188.38, episodes: 478\n",
      "57160: reward: 200.00, mean_100: 188.38, episodes: 479\n",
      "57344: reward: 183.00, mean_100: 188.48, episodes: 480\n",
      "57545: reward: 200.00, mean_100: 188.48, episodes: 481\n",
      "57689: reward: 143.00, mean_100: 187.91, episodes: 482\n",
      "57847: reward: 157.00, mean_100: 187.48, episodes: 483\n",
      "58005: reward: 157.00, mean_100: 187.56, episodes: 484\n",
      "58154: reward: 148.00, mean_100: 187.04, episodes: 485\n",
      "58355: reward: 200.00, mean_100: 187.07, episodes: 486\n",
      "58492: reward: 136.00, mean_100: 186.43, episodes: 487\n",
      "58673: reward: 180.00, mean_100: 186.23, episodes: 488\n",
      "58874: reward: 200.00, mean_100: 186.24, episodes: 489\n",
      "59026: reward: 151.00, mean_100: 186.34, episodes: 490\n",
      "59221: reward: 194.00, mean_100: 186.99, episodes: 491\n",
      "59422: reward: 200.00, mean_100: 186.99, episodes: 492\n",
      "59587: reward: 164.00, mean_100: 186.64, episodes: 493\n",
      "59788: reward: 200.00, mean_100: 187.18, episodes: 494\n",
      "59989: reward: 200.00, mean_100: 187.32, episodes: 495\n",
      "60190: reward: 200.00, mean_100: 187.95, episodes: 496\n",
      "60391: reward: 200.00, mean_100: 187.95, episodes: 497\n",
      "60592: reward: 200.00, mean_100: 187.98, episodes: 498\n",
      "60742: reward: 149.00, mean_100: 187.47, episodes: 499\n",
      "60943: reward: 200.00, mean_100: 187.47, episodes: 500\n",
      "61144: reward: 200.00, mean_100: 187.47, episodes: 501\n",
      "61345: reward: 200.00, mean_100: 187.47, episodes: 502\n",
      "61546: reward: 200.00, mean_100: 187.47, episodes: 503\n",
      "61747: reward: 200.00, mean_100: 187.47, episodes: 504\n",
      "61948: reward: 200.00, mean_100: 187.47, episodes: 505\n",
      "62149: reward: 200.00, mean_100: 187.47, episodes: 506\n",
      "62350: reward: 200.00, mean_100: 187.63, episodes: 507\n",
      "62551: reward: 200.00, mean_100: 187.63, episodes: 508\n",
      "62752: reward: 200.00, mean_100: 187.94, episodes: 509\n",
      "62953: reward: 200.00, mean_100: 187.94, episodes: 510\n",
      "63154: reward: 200.00, mean_100: 187.94, episodes: 511\n",
      "63355: reward: 200.00, mean_100: 187.94, episodes: 512\n",
      "63556: reward: 200.00, mean_100: 187.94, episodes: 513\n",
      "63757: reward: 200.00, mean_100: 187.94, episodes: 514\n",
      "63946: reward: 188.00, mean_100: 187.82, episodes: 515\n",
      "64147: reward: 200.00, mean_100: 187.82, episodes: 516\n",
      "64348: reward: 200.00, mean_100: 187.82, episodes: 517\n",
      "64549: reward: 200.00, mean_100: 187.82, episodes: 518\n",
      "64750: reward: 200.00, mean_100: 188.03, episodes: 519\n",
      "64951: reward: 200.00, mean_100: 188.03, episodes: 520\n",
      "65152: reward: 200.00, mean_100: 188.58, episodes: 521\n",
      "65353: reward: 200.00, mean_100: 188.73, episodes: 522\n",
      "65554: reward: 200.00, mean_100: 188.73, episodes: 523\n",
      "65751: reward: 196.00, mean_100: 188.69, episodes: 524\n",
      "65952: reward: 200.00, mean_100: 188.69, episodes: 525\n",
      "66153: reward: 200.00, mean_100: 188.69, episodes: 526\n",
      "66333: reward: 179.00, mean_100: 188.48, episodes: 527\n",
      "66534: reward: 200.00, mean_100: 188.48, episodes: 528\n",
      "66718: reward: 183.00, mean_100: 188.31, episodes: 529\n",
      "66914: reward: 195.00, mean_100: 188.26, episodes: 530\n",
      "67081: reward: 166.00, mean_100: 187.92, episodes: 531\n",
      "67225: reward: 143.00, mean_100: 187.35, episodes: 532\n",
      "67364: reward: 138.00, mean_100: 186.73, episodes: 533\n",
      "67496: reward: 131.00, mean_100: 186.04, episodes: 534\n",
      "67675: reward: 178.00, mean_100: 185.82, episodes: 535\n",
      "67757: reward:  81.00, mean_100: 184.63, episodes: 536\n",
      "67861: reward: 103.00, mean_100: 183.66, episodes: 537\n",
      "67992: reward: 130.00, mean_100: 182.96, episodes: 538\n",
      "68093: reward: 100.00, mean_100: 181.96, episodes: 539\n",
      "68225: reward: 131.00, mean_100: 181.27, episodes: 540\n",
      "68373: reward: 147.00, mean_100: 180.74, episodes: 541\n",
      "68525: reward: 151.00, mean_100: 180.25, episodes: 542\n",
      "68672: reward: 146.00, mean_100: 179.71, episodes: 543\n",
      "68827: reward: 154.00, mean_100: 179.25, episodes: 544\n",
      "68981: reward: 153.00, mean_100: 178.78, episodes: 545\n",
      "69145: reward: 163.00, mean_100: 178.71, episodes: 546\n",
      "69346: reward: 200.00, mean_100: 178.74, episodes: 547\n",
      "69543: reward: 196.00, mean_100: 178.70, episodes: 548\n",
      "69699: reward: 155.00, mean_100: 178.25, episodes: 549\n",
      "69900: reward: 200.00, mean_100: 178.25, episodes: 550\n",
      "70094: reward: 193.00, mean_100: 178.18, episodes: 551\n",
      "70295: reward: 200.00, mean_100: 178.18, episodes: 552\n",
      "70478: reward: 182.00, mean_100: 178.00, episodes: 553\n",
      "70679: reward: 200.00, mean_100: 178.00, episodes: 554\n",
      "70855: reward: 175.00, mean_100: 177.75, episodes: 555\n",
      "70997: reward: 141.00, mean_100: 177.16, episodes: 556\n",
      "71198: reward: 200.00, mean_100: 177.16, episodes: 557\n",
      "71399: reward: 200.00, mean_100: 178.01, episodes: 558\n",
      "71600: reward: 200.00, mean_100: 178.34, episodes: 559\n",
      "71801: reward: 200.00, mean_100: 178.95, episodes: 560\n",
      "72002: reward: 200.00, mean_100: 179.63, episodes: 561\n",
      "72203: reward: 200.00, mean_100: 179.63, episodes: 562\n",
      "72404: reward: 200.00, mean_100: 179.91, episodes: 563\n",
      "72605: reward: 200.00, mean_100: 180.53, episodes: 564\n",
      "72806: reward: 200.00, mean_100: 180.59, episodes: 565\n",
      "73007: reward: 200.00, mean_100: 180.59, episodes: 566\n",
      "73208: reward: 200.00, mean_100: 180.59, episodes: 567\n",
      "73409: reward: 200.00, mean_100: 181.43, episodes: 568\n",
      "73610: reward: 200.00, mean_100: 181.43, episodes: 569\n",
      "73811: reward: 200.00, mean_100: 181.43, episodes: 570\n",
      "74012: reward: 200.00, mean_100: 181.43, episodes: 571\n",
      "74213: reward: 200.00, mean_100: 181.73, episodes: 572\n",
      "74414: reward: 200.00, mean_100: 181.74, episodes: 573\n",
      "74605: reward: 190.00, mean_100: 181.94, episodes: 574\n",
      "74797: reward: 191.00, mean_100: 181.85, episodes: 575\n",
      "74998: reward: 200.00, mean_100: 182.08, episodes: 576\n",
      "75191: reward: 192.00, mean_100: 182.18, episodes: 577\n",
      "75392: reward: 200.00, mean_100: 183.33, episodes: 578\n",
      "75593: reward: 200.00, mean_100: 183.33, episodes: 579\n",
      "75794: reward: 200.00, mean_100: 183.50, episodes: 580\n",
      "75995: reward: 200.00, mean_100: 183.50, episodes: 581\n",
      "76196: reward: 200.00, mean_100: 184.07, episodes: 582\n",
      "76397: reward: 200.00, mean_100: 184.50, episodes: 583\n",
      "76598: reward: 200.00, mean_100: 184.93, episodes: 584\n",
      "76799: reward: 200.00, mean_100: 185.45, episodes: 585\n",
      "77000: reward: 200.00, mean_100: 185.45, episodes: 586\n",
      "77201: reward: 200.00, mean_100: 186.09, episodes: 587\n",
      "77300: reward:  98.00, mean_100: 185.27, episodes: 588\n",
      "77501: reward: 200.00, mean_100: 185.27, episodes: 589\n",
      "77702: reward: 200.00, mean_100: 185.76, episodes: 590\n",
      "77903: reward: 200.00, mean_100: 185.82, episodes: 591\n",
      "78104: reward: 200.00, mean_100: 185.82, episodes: 592\n",
      "78305: reward: 200.00, mean_100: 186.18, episodes: 593\n",
      "78506: reward: 200.00, mean_100: 186.18, episodes: 594\n",
      "78707: reward: 200.00, mean_100: 186.18, episodes: 595\n",
      "78908: reward: 200.00, mean_100: 186.18, episodes: 596\n",
      "79109: reward: 200.00, mean_100: 186.18, episodes: 597\n",
      "79310: reward: 200.00, mean_100: 186.18, episodes: 598\n",
      "79511: reward: 200.00, mean_100: 186.69, episodes: 599\n",
      "79712: reward: 200.00, mean_100: 186.69, episodes: 600\n",
      "79913: reward: 200.00, mean_100: 186.69, episodes: 601\n",
      "80102: reward: 188.00, mean_100: 186.57, episodes: 602\n",
      "80301: reward: 198.00, mean_100: 186.55, episodes: 603\n",
      "80469: reward: 167.00, mean_100: 186.22, episodes: 604\n",
      "80609: reward: 139.00, mean_100: 185.61, episodes: 605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80779: reward: 169.00, mean_100: 185.30, episodes: 606\n",
      "80926: reward: 146.00, mean_100: 184.76, episodes: 607\n",
      "81065: reward: 138.00, mean_100: 184.14, episodes: 608\n",
      "81198: reward: 132.00, mean_100: 183.46, episodes: 609\n",
      "81338: reward: 139.00, mean_100: 182.85, episodes: 610\n",
      "81474: reward: 135.00, mean_100: 182.20, episodes: 611\n",
      "81604: reward: 129.00, mean_100: 181.49, episodes: 612\n",
      "81735: reward: 130.00, mean_100: 180.79, episodes: 613\n",
      "81885: reward: 149.00, mean_100: 180.28, episodes: 614\n",
      "82034: reward: 148.00, mean_100: 179.88, episodes: 615\n",
      "82163: reward: 128.00, mean_100: 179.16, episodes: 616\n",
      "82296: reward: 132.00, mean_100: 178.48, episodes: 617\n",
      "82465: reward: 168.00, mean_100: 178.16, episodes: 618\n",
      "82666: reward: 200.00, mean_100: 178.16, episodes: 619\n",
      "82867: reward: 200.00, mean_100: 178.16, episodes: 620\n",
      "83007: reward: 139.00, mean_100: 177.55, episodes: 621\n",
      "83184: reward: 176.00, mean_100: 177.31, episodes: 622\n",
      "83365: reward: 180.00, mean_100: 177.11, episodes: 623\n",
      "83506: reward: 140.00, mean_100: 176.55, episodes: 624\n",
      "83666: reward: 159.00, mean_100: 176.14, episodes: 625\n",
      "83792: reward: 125.00, mean_100: 175.39, episodes: 626\n",
      "83950: reward: 157.00, mean_100: 175.17, episodes: 627\n",
      "84151: reward: 200.00, mean_100: 175.17, episodes: 628\n",
      "84299: reward: 147.00, mean_100: 174.81, episodes: 629\n",
      "84483: reward: 183.00, mean_100: 174.69, episodes: 630\n",
      "84660: reward: 176.00, mean_100: 174.79, episodes: 631\n",
      "84854: reward: 193.00, mean_100: 175.29, episodes: 632\n",
      "85055: reward: 200.00, mean_100: 175.91, episodes: 633\n",
      "85210: reward: 154.00, mean_100: 176.14, episodes: 634\n",
      "85411: reward: 200.00, mean_100: 176.36, episodes: 635\n",
      "85593: reward: 181.00, mean_100: 177.36, episodes: 636\n",
      "85794: reward: 200.00, mean_100: 178.33, episodes: 637\n",
      "85995: reward: 200.00, mean_100: 179.03, episodes: 638\n",
      "86196: reward: 200.00, mean_100: 180.03, episodes: 639\n",
      "86397: reward: 200.00, mean_100: 180.72, episodes: 640\n",
      "86598: reward: 200.00, mean_100: 181.25, episodes: 641\n",
      "86799: reward: 200.00, mean_100: 181.74, episodes: 642\n",
      "87000: reward: 200.00, mean_100: 182.28, episodes: 643\n",
      "87201: reward: 200.00, mean_100: 182.74, episodes: 644\n",
      "87402: reward: 200.00, mean_100: 183.21, episodes: 645\n",
      "87603: reward: 200.00, mean_100: 183.58, episodes: 646\n",
      "87804: reward: 200.00, mean_100: 183.58, episodes: 647\n",
      "88005: reward: 200.00, mean_100: 183.62, episodes: 648\n",
      "88206: reward: 200.00, mean_100: 184.07, episodes: 649\n",
      "88407: reward: 200.00, mean_100: 184.07, episodes: 650\n",
      "88608: reward: 200.00, mean_100: 184.14, episodes: 651\n",
      "88809: reward: 200.00, mean_100: 184.14, episodes: 652\n",
      "89010: reward: 200.00, mean_100: 184.32, episodes: 653\n",
      "89198: reward: 187.00, mean_100: 184.19, episodes: 654\n",
      "89395: reward: 196.00, mean_100: 184.40, episodes: 655\n",
      "89511: reward: 115.00, mean_100: 184.14, episodes: 656\n",
      "89698: reward: 186.00, mean_100: 184.00, episodes: 657\n",
      "89869: reward: 170.00, mean_100: 183.70, episodes: 658\n",
      "90008: reward: 138.00, mean_100: 183.08, episodes: 659\n",
      "90133: reward: 124.00, mean_100: 182.32, episodes: 660\n",
      "90239: reward: 105.00, mean_100: 181.37, episodes: 661\n",
      "90387: reward: 147.00, mean_100: 180.84, episodes: 662\n",
      "90418: reward:  30.00, mean_100: 179.14, episodes: 663\n",
      "90544: reward: 125.00, mean_100: 178.39, episodes: 664\n",
      "90674: reward: 129.00, mean_100: 177.68, episodes: 665\n",
      "90801: reward: 126.00, mean_100: 176.94, episodes: 666\n",
      "90958: reward: 156.00, mean_100: 176.50, episodes: 667\n",
      "91071: reward: 112.00, mean_100: 175.62, episodes: 668\n",
      "91196: reward: 124.00, mean_100: 174.86, episodes: 669\n",
      "91343: reward: 146.00, mean_100: 174.32, episodes: 670\n",
      "91479: reward: 135.00, mean_100: 173.67, episodes: 671\n",
      "91607: reward: 127.00, mean_100: 172.94, episodes: 672\n",
      "91804: reward: 196.00, mean_100: 172.90, episodes: 673\n",
      "92005: reward: 200.00, mean_100: 173.00, episodes: 674\n",
      "92165: reward: 159.00, mean_100: 172.68, episodes: 675\n",
      "92313: reward: 147.00, mean_100: 172.15, episodes: 676\n",
      "92514: reward: 200.00, mean_100: 172.23, episodes: 677\n",
      "92693: reward: 178.00, mean_100: 172.01, episodes: 678\n",
      "92894: reward: 200.00, mean_100: 172.01, episodes: 679\n",
      "93054: reward: 159.00, mean_100: 171.60, episodes: 680\n",
      "93227: reward: 172.00, mean_100: 171.32, episodes: 681\n",
      "93404: reward: 176.00, mean_100: 171.08, episodes: 682\n",
      "93605: reward: 200.00, mean_100: 171.08, episodes: 683\n",
      "93796: reward: 190.00, mean_100: 170.98, episodes: 684\n",
      "93993: reward: 196.00, mean_100: 170.94, episodes: 685\n",
      "94152: reward: 158.00, mean_100: 170.52, episodes: 686\n",
      "94325: reward: 172.00, mean_100: 170.24, episodes: 687\n",
      "94475: reward: 149.00, mean_100: 170.75, episodes: 688\n",
      "94627: reward: 151.00, mean_100: 170.26, episodes: 689\n",
      "94784: reward: 156.00, mean_100: 169.82, episodes: 690\n",
      "94917: reward: 132.00, mean_100: 169.14, episodes: 691\n",
      "95089: reward: 171.00, mean_100: 168.85, episodes: 692\n",
      "95271: reward: 181.00, mean_100: 168.66, episodes: 693\n",
      "95436: reward: 164.00, mean_100: 168.30, episodes: 694\n",
      "95612: reward: 175.00, mean_100: 168.05, episodes: 695\n",
      "95758: reward: 145.00, mean_100: 167.50, episodes: 696\n",
      "95959: reward: 200.00, mean_100: 167.50, episodes: 697\n",
      "96155: reward: 195.00, mean_100: 167.45, episodes: 698\n",
      "96356: reward: 200.00, mean_100: 167.45, episodes: 699\n",
      "96501: reward: 144.00, mean_100: 166.89, episodes: 700\n",
      "96689: reward: 187.00, mean_100: 166.76, episodes: 701\n",
      "96872: reward: 182.00, mean_100: 166.70, episodes: 702\n",
      "97027: reward: 154.00, mean_100: 166.26, episodes: 703\n",
      "97198: reward: 170.00, mean_100: 166.29, episodes: 704\n",
      "97309: reward: 110.00, mean_100: 166.00, episodes: 705\n",
      "97451: reward: 141.00, mean_100: 165.72, episodes: 706\n",
      "97630: reward: 178.00, mean_100: 166.04, episodes: 707\n",
      "97747: reward: 116.00, mean_100: 165.82, episodes: 708\n",
      "97907: reward: 159.00, mean_100: 166.09, episodes: 709\n",
      "98090: reward: 182.00, mean_100: 166.52, episodes: 710\n",
      "98281: reward: 190.00, mean_100: 167.07, episodes: 711\n",
      "98482: reward: 200.00, mean_100: 167.78, episodes: 712\n",
      "98683: reward: 200.00, mean_100: 168.48, episodes: 713\n",
      "98884: reward: 200.00, mean_100: 168.99, episodes: 714\n",
      "99085: reward: 200.00, mean_100: 169.51, episodes: 715\n",
      "99286: reward: 200.00, mean_100: 170.23, episodes: 716\n",
      "99487: reward: 200.00, mean_100: 170.91, episodes: 717\n",
      "99688: reward: 200.00, mean_100: 171.23, episodes: 718\n",
      "99889: reward: 200.00, mean_100: 171.23, episodes: 719\n",
      "100090: reward: 200.00, mean_100: 171.23, episodes: 720\n",
      "100272: reward: 181.00, mean_100: 171.65, episodes: 721\n",
      "100473: reward: 200.00, mean_100: 171.89, episodes: 722\n",
      "100674: reward: 200.00, mean_100: 172.09, episodes: 723\n",
      "100875: reward: 200.00, mean_100: 172.69, episodes: 724\n",
      "101076: reward: 200.00, mean_100: 173.10, episodes: 725\n",
      "101277: reward: 200.00, mean_100: 173.85, episodes: 726\n",
      "101478: reward: 200.00, mean_100: 174.28, episodes: 727\n",
      "101679: reward: 200.00, mean_100: 174.28, episodes: 728\n",
      "101880: reward: 200.00, mean_100: 174.81, episodes: 729\n",
      "102081: reward: 200.00, mean_100: 174.98, episodes: 730\n",
      "102282: reward: 200.00, mean_100: 175.22, episodes: 731\n",
      "102483: reward: 200.00, mean_100: 175.29, episodes: 732\n",
      "102684: reward: 200.00, mean_100: 175.29, episodes: 733\n",
      "102885: reward: 200.00, mean_100: 175.75, episodes: 734\n",
      "103086: reward: 200.00, mean_100: 175.75, episodes: 735\n",
      "103287: reward: 200.00, mean_100: 175.94, episodes: 736\n",
      "103455: reward: 167.00, mean_100: 175.61, episodes: 737\n",
      "103640: reward: 184.00, mean_100: 175.45, episodes: 738\n",
      "103841: reward: 200.00, mean_100: 175.45, episodes: 739\n",
      "104042: reward: 200.00, mean_100: 175.45, episodes: 740\n",
      "104243: reward: 200.00, mean_100: 175.45, episodes: 741\n",
      "104444: reward: 200.00, mean_100: 175.45, episodes: 742\n",
      "104645: reward: 200.00, mean_100: 175.45, episodes: 743\n",
      "104846: reward: 200.00, mean_100: 175.45, episodes: 744\n",
      "105047: reward: 200.00, mean_100: 175.45, episodes: 745\n",
      "105248: reward: 200.00, mean_100: 175.45, episodes: 746\n",
      "105449: reward: 200.00, mean_100: 175.45, episodes: 747\n",
      "105650: reward: 200.00, mean_100: 175.45, episodes: 748\n",
      "105851: reward: 200.00, mean_100: 175.45, episodes: 749\n",
      "106052: reward: 200.00, mean_100: 175.45, episodes: 750\n",
      "106253: reward: 200.00, mean_100: 175.45, episodes: 751\n",
      "106454: reward: 200.00, mean_100: 175.45, episodes: 752\n",
      "106655: reward: 200.00, mean_100: 175.45, episodes: 753\n",
      "106856: reward: 200.00, mean_100: 175.58, episodes: 754\n",
      "107057: reward: 200.00, mean_100: 175.62, episodes: 755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107258: reward: 200.00, mean_100: 176.47, episodes: 756\n",
      "107459: reward: 200.00, mean_100: 176.61, episodes: 757\n",
      "107660: reward: 200.00, mean_100: 176.91, episodes: 758\n",
      "107861: reward: 200.00, mean_100: 177.53, episodes: 759\n",
      "108062: reward: 200.00, mean_100: 178.29, episodes: 760\n",
      "108263: reward: 200.00, mean_100: 179.24, episodes: 761\n",
      "108464: reward: 200.00, mean_100: 179.77, episodes: 762\n",
      "108665: reward: 200.00, mean_100: 181.47, episodes: 763\n",
      "108866: reward: 200.00, mean_100: 182.22, episodes: 764\n",
      "109067: reward: 200.00, mean_100: 182.93, episodes: 765\n",
      "109268: reward: 200.00, mean_100: 183.67, episodes: 766\n",
      "109469: reward: 200.00, mean_100: 184.11, episodes: 767\n",
      "109670: reward: 200.00, mean_100: 184.99, episodes: 768\n",
      "109871: reward: 200.00, mean_100: 185.75, episodes: 769\n",
      "110072: reward: 200.00, mean_100: 186.29, episodes: 770\n",
      "110273: reward: 200.00, mean_100: 186.94, episodes: 771\n",
      "110474: reward: 200.00, mean_100: 187.67, episodes: 772\n",
      "110675: reward: 200.00, mean_100: 187.71, episodes: 773\n",
      "110876: reward: 200.00, mean_100: 187.71, episodes: 774\n",
      "111077: reward: 200.00, mean_100: 188.12, episodes: 775\n",
      "111278: reward: 200.00, mean_100: 188.65, episodes: 776\n",
      "111479: reward: 200.00, mean_100: 188.65, episodes: 777\n",
      "111680: reward: 200.00, mean_100: 188.87, episodes: 778\n",
      "111881: reward: 200.00, mean_100: 188.87, episodes: 779\n",
      "112082: reward: 200.00, mean_100: 189.28, episodes: 780\n",
      "112283: reward: 200.00, mean_100: 189.56, episodes: 781\n",
      "112484: reward: 200.00, mean_100: 189.80, episodes: 782\n",
      "112685: reward: 200.00, mean_100: 189.80, episodes: 783\n",
      "112886: reward: 200.00, mean_100: 189.90, episodes: 784\n",
      "113087: reward: 200.00, mean_100: 189.94, episodes: 785\n",
      "113269: reward: 181.00, mean_100: 190.17, episodes: 786\n",
      "113470: reward: 200.00, mean_100: 190.45, episodes: 787\n",
      "113671: reward: 200.00, mean_100: 190.96, episodes: 788\n",
      "113872: reward: 200.00, mean_100: 191.45, episodes: 789\n",
      "114060: reward: 187.00, mean_100: 191.76, episodes: 790\n",
      "114261: reward: 200.00, mean_100: 192.44, episodes: 791\n",
      "114455: reward: 193.00, mean_100: 192.66, episodes: 792\n",
      "114656: reward: 200.00, mean_100: 192.85, episodes: 793\n",
      "114857: reward: 200.00, mean_100: 193.21, episodes: 794\n",
      "115058: reward: 200.00, mean_100: 193.46, episodes: 795\n",
      "115259: reward: 200.00, mean_100: 194.01, episodes: 796\n",
      "115460: reward: 200.00, mean_100: 194.01, episodes: 797\n",
      "115661: reward: 200.00, mean_100: 194.06, episodes: 798\n",
      "115862: reward: 200.00, mean_100: 194.06, episodes: 799\n",
      "116063: reward: 200.00, mean_100: 194.62, episodes: 800\n",
      "116264: reward: 200.00, mean_100: 194.75, episodes: 801\n",
      "116465: reward: 200.00, mean_100: 194.93, episodes: 802\n",
      "116666: reward: 200.00, mean_100: 195.39, episodes: 803\n",
      "Solved in 116666 steps and 803 episodes!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "env = gym.make('CartPole-v0')\n",
    "net = PGN(env.observation_space.shape[0], env.action_space.n).to(device)\n",
    "\n",
    "agent = ptan.agent.PolicyAgent(net,preprocessor=ptan.agent.float32_preprocessor,device=device)\n",
    "\n",
    "exp_source = ptan.experience.ExperienceSourceFirstLast(env,agent,gamma=GAMMA,\n",
    "                                                       steps_count=BELLMAN_STEPS)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "total_rewards = []\n",
    "step_rewards = []\n",
    "baseline_buf = MeanBuffer(BASELINE_STEPS)\n",
    "step_idx = 0\n",
    "done_episodes = 0\n",
    "\n",
    "batch_states, batch_actions, batch_scales = [], [], []\n",
    "for step_idx, exp in enumerate(exp_source):\n",
    "    baseline_buf.add(exp.reward)\n",
    "    baseline = baseline_buf.mean()\n",
    "    batch_states.append(exp.state)\n",
    "    batch_actions.append(exp.action)\n",
    "    batch_scales.append(exp.reward - baseline)\n",
    "  \n",
    "    episode_rewards = exp_source.pop_total_rewards()\n",
    "    if episode_rewards:\n",
    "        done_episodes += 1\n",
    "        reward = episode_rewards[0]\n",
    "        total_rewards.append(reward)\n",
    "        mean_rewards = float(np.mean(total_rewards[-100:]))\n",
    "        print(\"%d: reward: %6.2f, mean_100: %6.2f, episodes: %d\" % (\n",
    "                step_idx, reward, mean_rewards, done_episodes))\n",
    "        if mean_rewards > TARGET_REWARD:\n",
    "            print(\"Solved in %d steps and %d episodes!\" % (step_idx, done_episodes))\n",
    "            break\n",
    "      \n",
    "    if len(batch_states) < BATCH_SIZE:\n",
    "        continue\n",
    "    \n",
    "    #copy training data to the GPU\n",
    "    states_v = torch.FloatTensor(batch_states).to(device)\n",
    "    batch_actions_t = torch.LongTensor(batch_actions).to(device)\n",
    "    batch_scale_v = torch.FloatTensor(batch_scales).to(device)\n",
    "\n",
    "    #apply gradient descent\n",
    "    optimizer.zero_grad()\n",
    "    #softmax output\n",
    "    \n",
    "    prob_v = net(states_v)\n",
    "    \n",
    "    #apply logarithm\n",
    "    log_prob_v = torch.log(prob_v)\n",
    "    #scale the log probs according to (reward - baseline)\n",
    "    log_prob_actions_v = batch_scale_v * log_prob_v[range(BATCH_SIZE), batch_actions_t]\n",
    "    #take the mean cross-entropy across all batches\n",
    "    loss_policy_v = -log_prob_actions_v.mean()\n",
    "\n",
    "    # subtract the entropy bonus from the loss function\n",
    "    entropy_v = -(prob_v * log_prob_v).sum(dim=1).mean()\n",
    "    entropy_loss_v = -ENTROPY_BETA * entropy_v\n",
    "    loss_v = loss_policy_v + entropy_loss_v\n",
    "\n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    batch_states.clear()\n",
    "    batch_actions.clear()\n",
    "    batch_scales.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
